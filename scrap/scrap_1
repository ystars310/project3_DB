
import requests, re, tqdm, os
import pandas as pd
import numpy as np 
from bs4 import BeautifulSoup
import time, random
df=pd.read_csv("source/origin/issue_date_asc_2017-2022_187045file.csv")
df = df[~df.duplicated(
    subset=['song_name', "artist_name"])].reset_index(drop=True)
# df["lyric"]= np.nan
# df["melon_song_id"]=np.nan
# new_df=pd.read_csv("results/output_4700.csv")
# df[:4700] = new_df[:4700].copy()
# new_df=pd.read_csv("results/output_6100.csv")
# df[4700:6100] = new_df[4700:6100].copy()
# df = pd.read_csv("output.csv",low_memory=False)
# new_df
url = "https://www.melon.com/search/total/index.htm"
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36",
]
headers = {
    "User-Agent":(
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \
                   (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'),
    "Referer":'https://www.melon.com/index.htm',
}
# jscallback = 'jQuery19109301051835844539_1749536945535'
def pre_processing(lyric_div):
    for comment in lyric_div.find_all(string=lambda text: isinstance(text, type(soup.Comment))):
        comment.extract()

    # <br> 태그를 줄바꿈으로 변환
    for br in lyric_div.find_all("br"):
        br.replace_with("\n")

    # 전체 텍스트 추출 및 앞뒤 공백 제거
    lyrics = lyric_div.get_text(separator="\n").strip()

    # 여러 줄바꿈을 하나로 정리 (선택사항)
    lyrics = re.sub(r'\n+', '\n', lyrics)
    return lyric_div
n=32900
for idx, (song_name, artist_name) in enumerate(tqdm.tqdm(df[["song_name","artist_name"]].values[n:]),n):
    time.sleep(random.uniform(1.0, 3))
    # if idx==2:
    #     break
    headers = {
        "Referer": "https://www.melon.com/index.htm",
        "User-Agent": random.choice(user_agents)  # 랜덤 User-Agent 선택
    }
    if not song_name is np.nan:
        query = f"{song_name.replace(" ","")} {artist_name.replace(" ","")}"
        query = re.sub(r'\([^)]*\)', '', query)
        params = {
            "q":query,
        "section": "",
            "searchGnbYn": "Y"
        }
        session = requests.Session()
        res = session.get(
            url, headers=headers, params=params)
        while res.status_code ==406:
            print(res.status_code)
            time.sleep(600)
            res = session.get(
                url, headers=headers, params=params)
        soup = BeautifulSoup(res.text, "html.parser")
        inputs = soup.select("input[name=input_check]")
        if len(inputs):
            song_id = inputs[0].get("value")
            df.loc[idx,"melon_song_id"] = song_id
            song_url=f"https://www.melon.com/song/detail.htm?songId={song_id}"
            song_res = requests.get(song_url, headers=headers)
            soup = BeautifulSoup(song_res.text, 'html.parser')
            lyric_div = soup.find('div', id='d_video_summary')
            if not lyric_div is None:
                lyric_div = pre_processing(lyric_div)
                df.loc[idx,"lyric"] = lyric_div.text
        if idx % 50 ==0:
            os.makedirs("results",exist_ok=True)
            df.to_csv(f"results/output_{idx}.csv",index=False, encoding="utf-8-sig")
            df.to_csv(f"output.csv",index=False, encoding="utf-8-sig")
