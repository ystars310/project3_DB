
import requests, re, tqdm, os
import pandas as pd
import numpy as np 
from bs4 import BeautifulSoup
import time, random
df=pd.read_csv("output.csv")
df["bugs_song_id"]=np.nan
url = "https://music.bugs.co.kr/search/track"
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36",
]
headers = {
    "User-Agent":(
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \
                   (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'),
    "Referer":'https://music.bugs.co.kr',
}
# jscallback = 'jQuery19109301051835844539_1749536945535'
def pre_processing(lyric_div):
    for comment in lyric_div.find_all(string=lambda text: isinstance(text, type(soup.Comment))):
        comment.extract()

    # <br> 태그를 줄바꿈으로 변환
    for br in lyric_div.find_all("br"):
        br.replace_with("\n")

    # 전체 텍스트 추출 및 앞뒤 공백 제거
    lyrics = lyric_div.get_text(separator="\n").strip()

    # 여러 줄바꿈을 하나로 정리 (선택사항)
    lyrics = re.sub(r'\n+', '\n', lyrics)
    return lyric_div
n=4750
for idx, (song_name, artist_name) in enumerate(tqdm.tqdm(df[["song_name","artist_name"]].values[n:]),n):
    time.sleep(random.uniform(0.8, 2))
    # if idx==2:
    #     break
    headers = {
        "Referer": "https://music.bugs.co.kr",
        "User-Agent": random.choice(user_agents)  # 랜덤 User-Agent 선택
    }
    query = f"{song_name.replace(" ","")} {artist_name.replace(" ","")}"
    query = re.sub(r'\([^)]*\)', '', query)
    params = {
        "q":query,
       "section": "",
        "searchGnbYn": "Y"
    }
    session = requests.Session()
    res = session.get(
        url, headers=headers, params=params)
    while res.status_code ==406:
        time.sleep(600)
        res = session.get(
            url, headers=headers, params=params)
        print(res.status_code)
    soup = BeautifulSoup(res.text, "html.parser")
    inputs = soup.select("table.list > tbody >tr .btnActions")
    if len(inputs):
        song_id = inputs[0].get("artist_id")
        df.loc[idx,"bugs_song_id"] = song_id
        song_url=f"https://music.bugs.co.kr/track/{song_id}"
        song_res = requests.get(song_url, headers=headers)
        soup = BeautifulSoup(song_res.text, 'html.parser')
        lyric_div = soup.select_one('#container > section.sectionPadding.contents.lyrics xmp')
        if not lyric_div is None:
            lyric_div = pre_processing(lyric_div)
            df.loc[idx,"lyric"] = lyric_div.text
    if idx % 50 ==0:
        os.makedirs("results",exist_ok=True)
        df.to_csv(f"results/output_{idx}.csv",index=False, encoding="utf-8-sig")
        df.to_csv(f"output.csv",index=False, encoding="utf-8-sig")
